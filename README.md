# HandlingMulticollinearity

Multicollinearity is a statistical phenomenon that occurs when two or more independent variables in a multiple regression model are highly correlated. In other words, these variables exhibit a strong linear relationship, making it difficult to isolate the individual effects of each variable on the dependent variable.


Inference:
• Inference focuses on understanding the relationships between the variables in a model.
It aims to draw conclusions about the underlying population or process that generated
the data.
• Inference often involves hypothesis testing, confidence intervals, and determining the significance of predictor variables.
• The primary goal is to provide insights about the structure of the data and the relationships between variables.
• Interpretability is a key concern when performing inference, as the objective js to understand the underlying mechanisms driving the data.
• Examples of inferential techniques include linear regression, logistic regression, and ANOVA.



•Prediction focuses on using a model to make accurate forecasts or estimates for new, unseen data.
•It aims to generalize the model to new instances, based on the patterns observed in the training data.
. Prediction often involves minimizing an error metric, such as mean squared error or cross-
entropy loss, to assess the accuracy of the model.
•The primary goal is to create an accurate and reliable model for predicting outcomes, rather than understanding the relationships between variables.
Interpretability may be less important in predictive modelling, as the main objective is to create accurate forecasts rather than understanding the underlying structure of the data.
• Examples of predictive techniques include decision trees, support vector machines, neural networks, and ensemble methods like random forests and gradient boosting machines.
